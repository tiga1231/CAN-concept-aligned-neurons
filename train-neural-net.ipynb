{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eac911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jupyter_black\n",
    "\n",
    "# jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c05e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.resnet import ResNet50_Weights\n",
    "from torch import nn\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-v0_8-colorblind')\n",
    "from natsort import natsorted\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b61cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vis = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef138d",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '/home/lim38/dataset/imagenet-val/'\n",
    "\n",
    "# Initialize transformations for data augmentation\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load the ImageNet Object Localization Challenge dataset\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=image_folder, transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=image_folder, transform=val_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9744f539",
   "metadata": {},
   "source": [
    "## Randomly split classes into two subsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d32a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_class_directories = natsorted(glob(f'{image_folder}/*/'))\n",
    "\n",
    "# random.seed(0)\n",
    "# n_classes = len(image_class_directories)\n",
    "# class_set1 = set(random.sample(range(n_classes), k=500)) # {0,1,2,3,8,9,12,...} w/ seed(0)\n",
    "# class_set2 = set(range(n_classes)) - set(class_set1) # complement of set1\n",
    "# print('classes in set1:', class_set1)\n",
    "# print('classes in set2:', class_set2)\n",
    "\n",
    "\n",
    "# image_subset1 = [i for i, [img, label] in enumerate(train_dataset.imgs) if label in class_set1]\n",
    "# image_subset2 = [i for i, [img, label] in enumerate(train_dataset.imgs) if label in class_set2]\n",
    "# train_dataset1 = torch.utils.data.Subset(train_dataset, image_subset1)\n",
    "# train_dataset2 = torch.utils.data.Subset(train_dataset, image_subset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c7efd",
   "metadata": {},
   "source": [
    "## train loader based on (sub)dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ff838",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset1, batch_size=batch_size, shuffle=True, num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db29cab",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=ResNet50_Weights.IMAGENET1K_V1\n",
    "weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846dad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ResNet50 model\n",
    "model = torchvision.models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "# model = torch.nn.DataParallel(model) # Parallelize training across multiple GPUs\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, batch_size=64, device=device):\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=False, num_workers=8\n",
    "    )\n",
    "    \n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = model(images)\n",
    "            preds = softmax(logits).argmax(dim=1)\n",
    "            correct += (preds==labels).sum().item()\n",
    "            total += images.shape[0]\n",
    "    accuracy = correct / total\n",
    "    return dict(\n",
    "        correct = correct,\n",
    "        total = total,\n",
    "        accuracy = accuracy\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c7b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_bar = tqdm(total=num_epochs)\n",
    "batch_bar = tqdm(total=len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model...\n",
    "losses = []\n",
    "loss_prev = None\n",
    "for epoch in range(num_epochs):\n",
    "    batch_bar.reset()\n",
    "    model.train()\n",
    "    for i, [inputs, labels] in enumerate(train_loader):\n",
    "        # Move input and label tensors to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero out the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # vis\n",
    "        loss = loss.item()\n",
    "        running_average_loss = loss_prev * 0.99 + loss * 0.01 if loss_prev is not None else loss\n",
    "        loss_prev = loss\n",
    "        losses.append(running_average_loss)\n",
    "\n",
    "\n",
    "        batch_bar.update() # +1\n",
    "    batch_bar.refresh() # force finish\n",
    "\n",
    "    # vis\n",
    "    if vis:\n",
    "        plt.plot(losses)\n",
    "        plt.show()\n",
    "\n",
    "    # By the end of every epoch, print the loss and accuracy, \n",
    "    if(type(loss) != float):\n",
    "        loss = loss.item()    \n",
    "    model.eval()\n",
    "    evaluation = evaluate(model, val_dataset)\n",
    "    correct, total, accuracy = evaluation['correct'], evaluation['total'], evaluation['accuracy']\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}\")\n",
    "    print(f'top1 accuracy: {accuracy:.4f} ({correct}/{total})')\n",
    "    \n",
    "    epoch_bar.update() # +1\n",
    "    \n",
    "print(f\"Finished Training, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a43f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
