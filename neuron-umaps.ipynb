{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfbd705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "from itertools import product\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from umap import UMAP\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "\n",
    "import data_utils\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.style.use(\"seaborn-v0_8-colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b091a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Load vocabulary\n",
    "\n",
    "# # with open(\"./data/20k.txt\") as f:\n",
    "# # with open(\"./data/nouns_and_adjectives.txt\") as f:\n",
    "# with open(\"./data/wordnet_hierarchy.txt\") as f:\n",
    "#     vocabulary = [v.strip() for v in f]\n",
    "# \", \".join(vocabulary[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a830aec0",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "natsorted(glob('my_data/*/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose the models to jointly (all layers in all models) compute UMAP on\n",
    "\n",
    "dir_in = 'my_data'\n",
    "\n",
    "# models = []\n",
    "# models += natsorted(glob('my_data/resnet*/'))\n",
    "# models += natsorted(glob('my_data/vit*/'))\n",
    "# models += natsorted(glob('my_data/googlenet*/'))\n",
    "# models += natsorted(glob('my_data/*attack*/'))\n",
    "# model_groups_to_compare = [models]\n",
    "\n",
    "model_groups_to_compare  = [\n",
    "    ['architectures', ['resnet34', 'resnet50', 'googlenet', 'vit_b_16']],\n",
    "    ['splits', ['resnet50_split0', 'resnet50_split1']],\n",
    "    ['artificial_vs_natural', ['resnet50_artificial', 'resnet50_natural']],\n",
    "    ['attacks', ['resnet50_under_attack', 'resnet50robust_under_attack']],\n",
    "]\n",
    "\n",
    "model_groups_to_compare = [\n",
    "    [group_name, [f'{dir_in}/{m}/' for m in models]]\n",
    "    for group_name, models in model_groups_to_compare\n",
    "]\n",
    "\n",
    "pprint(model_groups_to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_and_rotate(xy):\n",
    "    xy = xy - xy.mean(axis=0)\n",
    "    best_rot = None\n",
    "    largest_aspect_ratio = -1\n",
    "    for angle in np.linspace(0, np.pi/2, 14):\n",
    "        rot = np.array([\n",
    "            [np.cos(angle), np.sin(angle)], \n",
    "            [-np.sin(angle), np.cos(angle)]\n",
    "        ])\n",
    "        xy_rot = xy @ rot\n",
    "        w = xy_rot[:,0].max() - xy_rot[:,0].min()\n",
    "        h = xy_rot[:,1].max() - xy_rot[:,1].min()\n",
    "        aspect_ratio = w/h\n",
    "        if aspect_ratio > largest_aspect_ratio:\n",
    "            largest_aspect_ratio = aspect_ratio\n",
    "            best_rot = rot\n",
    "    xy = xy @ best_rot\n",
    "    return xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_out = 'my_data/neuron_umaps'\n",
    "os.makedirs(dir_out, exist_ok=True)\n",
    "\n",
    "for group_name, model_group in tqdm(model_groups_to_compare):\n",
    "    ## load data\n",
    "    model_layer_neurons = []\n",
    "    sim_data = []\n",
    "    for m in model_group:\n",
    "        sim = torch.load(f\"./{m}/all_layer_similarities.pt\")\n",
    "        m = m.split('/')[-2]\n",
    "        model_layer_neurons += [[m, s['layer'], s['similarities'].shape[0]] for s in sim]\n",
    "        sim_data += [s['similarities'] for s in sim]\n",
    "    sim_data = torch.cat(sim_data)\n",
    "    sim_data = sim_data.numpy()\n",
    "    \n",
    "    print(\n",
    "        'Computing UMAP of group', model_group, '\\n',\n",
    "        'data shape', sim_data.shape, '\\n',\n",
    "        'layers', model_layer_neurons[:2], '...'\n",
    "    )\n",
    "    \n",
    "    xy = UMAP(\n",
    "        n_neighbors=300,\n",
    "        min_dist=0.8, \n",
    "        n_components=2,\n",
    "    ).fit_transform(sim_data)\n",
    "    xy = center_and_rotate(xy)\n",
    "    \n",
    "#     xy = PCA().fit_transform(xy)\n",
    "#     ## PCA makes array in fortran order, turning in back to \"C order\" :((\n",
    "#     xy = np.ascontiguousarray(xy) \n",
    "\n",
    "    plt.scatter(\n",
    "        xy[:,0], \n",
    "        xy[:,1], \n",
    "        s=0.5,\n",
    "    )\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    os.makedirs(f\"{dir_out}/{group_name}\", exist_ok=True)\n",
    "    plt.savefig(f\"{dir_out}/{group_name}/plot.png\", dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    ## vis/save umap to file\n",
    "    vis = False\n",
    "    start = 0\n",
    "    n_neurons_per_layer = [s[2] for s in model_layer_neurons]\n",
    "    for start,s in zip([0,*np.cumsum(n_neurons_per_layer)],model_layer_neurons) :\n",
    "        \n",
    "        n = s[2]\n",
    "        xy_layer = xy[start:start+n]\n",
    "        \n",
    "        fn = f'{s[0]}_{s[1]}'\n",
    "        os.makedirs(f\"{dir_out}/{group_name}\", exist_ok=True)\n",
    "        out_filepath = f\"{dir_out}/{group_name}/{fn}.npy\"\n",
    "        np.save(out_filepath, xy_layer.astype(np.float16))\n",
    "        print('save umap in:', out_filepath)\n",
    "        \n",
    "        if vis:\n",
    "            plt.figure(figsize=[3,3])\n",
    "            plt.scatter(\n",
    "                xy_layer[:,0], \n",
    "                xy_layer[:,1], \n",
    "                s=1,\n",
    "                label=f'{s[0]}, {s[1]}'\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.axis('equal')\n",
    "            plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: rotate:\n",
    "# # 1. center\n",
    "# # 2. for angle in angles, rotate data\n",
    "# # .compute aspect ratio\n",
    "# # keep best angle and largest aspect ratio\n",
    "\n",
    "# def center_and_rotate(xy):\n",
    "#     xy = xy - xy.mean(axis=0)\n",
    "#     best_rot = None\n",
    "#     largest_aspect_ratio = -1\n",
    "#     for angle in np.linspace(0, np.pi/2, 14):\n",
    "#         rot = np.array([\n",
    "#             [np.cos(angle), np.sin(angle)], \n",
    "#             [-np.sin(angle), np.cos(angle)]\n",
    "#         ])\n",
    "#         xy_rot = xy @ rot\n",
    "#         w = xy_rot[:,0].max() - xy_rot[:,0].min()\n",
    "#         h = xy_rot[:,1].max() - xy_rot[:,1].min()\n",
    "#         aspect_ratio = w/h\n",
    "#         if aspect_ratio > largest_aspect_ratio:\n",
    "#             largest_aspect_ratio = aspect_ratio\n",
    "#             best_rot = rot\n",
    "#     xy = xy @ best_rot\n",
    "#     return xy\n",
    "\n",
    "# plt.scatter(\n",
    "#     xy[:,0], \n",
    "#     xy[:,1], \n",
    "#     s=0.5,\n",
    "# )\n",
    "# plt.axis('equal')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdcc341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(\n",
    "#     xy[:,0], \n",
    "#     xy[:,1], \n",
    "#     s=0.1,\n",
    "# )\n",
    "# plt.axis('equal')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b22abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = torch.cat([torch.ones(s[2])+i for i,s in enumerate(model_layer_neurons)]).numpy()\n",
    "# s = torch.cat([torch.ones(s[2])+i for i,s in enumerate(model_layer_neurons)]).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bc6d95",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb4d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## UMAP by activation\n",
    "\n",
    "# # layer1 = torch.load('./my_data/resnet50_under_attack/imagenet_val_attack_resnet50_layer4.pt')\n",
    "# # layer2 = torch.load('./my_data/resnet50robust_under_attack/imagenet_val_attack_resnet50robust_layer4.pt')\n",
    "\n",
    "# # layer1 = torch.load('./my_data/resnet50/imagenet_val_resnet50_layer4.pt')\n",
    "# # layer2 = torch.load('./my_data/resnet50robust/imagenet_val_resnet50robust_layer4.pt')\n",
    "\n",
    "# layer1 = torch.load('./my_data/resnet34/imagenet_val_resnet34_layer4.pt')\n",
    "# layer2 = torch.load('./my_data/resnet50/imagenet_val_resnet50_layer4.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297716a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# umap_data = torch.cat([layer1.t(), layer2.t()]).cpu().numpy()\n",
    "# umap_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8277d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# umap = UMAP(n_neighbors=100).fit_transform(umap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ddd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c=torch.concat([\n",
    "#     torch.zeros(layer1.shape[1]), \n",
    "#     torch.ones(layer2.shape[1])\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(\n",
    "#     umap[:,0], \n",
    "#     umap[:,1], \n",
    "#     s=5,\n",
    "#     c=c,\n",
    "#     cmap='tab10'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b0079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0f38e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer-pairwise UMAP\n",
    "# umaps = []\n",
    "# for m1, m2 in product(models, models):\n",
    "#     if m1>m2:\n",
    "#         continue\n",
    "                \n",
    "#     ## Load neuron-concept similarity\n",
    "#     sim1 = torch.load(f\"./{m1}/all_layer_similarities.pt\")\n",
    "#     sim2 = torch.load(f\"./{m2}/all_layer_similarities.pt\")\n",
    "#     layer_names1 = [s['layer'] for s in sim1]\n",
    "#     layer_names2 = [s['layer'] for s in sim2]\n",
    "    \n",
    "#     m1, m2 = m1.split('/')[-2], m2.split('/')[-2]\n",
    "#     for l1, l2 in product(\n",
    "#         range(len(layer_names1)), \n",
    "#         range(len(layer_names2))\n",
    "#     ):\n",
    "#         if l1>l2: \n",
    "#             continue\n",
    "        \n",
    "#         data = torch.cat([sim1[l1][\"similarities\"],sim2[l2][\"similarities\"]]).numpy()\n",
    "#         print(data.shape)\n",
    "#         xy = UMAP(n_components=2, min_dist=0.3).fit_transform(data)\n",
    "#         ## num neurons\n",
    "#         n1 = sim1[l1][\"similarities\"].shape[0]\n",
    "#         n2 = sim2[l2][\"similarities\"].shape[0]\n",
    "#         plt.figure(figsize=[4,4])\n",
    "#         plt.scatter(\n",
    "#             xy[:,0], \n",
    "#             xy[:,1], \n",
    "#             s=torch.cat([10+torch.zeros(n1), 5+torch.zeros(n2)]), \n",
    "#             c=torch.cat([torch.zeros(n1), torch.ones(n2)]), \n",
    "#             cmap='tab10'\n",
    "#         )\n",
    "#         plt.title([m1, m2, layer_names1[l1], layer_names2[l2]])\n",
    "#         plt.show()\n",
    "        \n",
    "#         umaps.append([m1, m2, layer_names1[l1], layer_names2[l2], xy])\n",
    "#         umaps.append([m2, m1, layer_names2[l2], layer_names1[l1], xy])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432881e",
   "metadata": {},
   "source": [
    "### Neuron UMAP, Each individual layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0404ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,[m1, m2, l1, l2, umap] in enumerate(umaps):\n",
    "#     plt.figure()\n",
    "#     plt.scatter(\n",
    "#         umap[:, 0],\n",
    "#         umap[:, 1],\n",
    "#         s=10,\n",
    "#         linewidth=0.1,\n",
    "#         edgecolors=\"#333\",\n",
    "#     )\n",
    "#     plt.axis(\"equal\")\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735e8246",
   "metadata": {},
   "source": [
    "## Save UMAP to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db18850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i,[m1, m2, l1, l2, umap] in enumerate(umaps):\n",
    "#     fn = f'{m1}_{l1}_{m2}_{l2}'\n",
    "#     np.save(f\"{dir_out}/{fn}.npy\", umap)\n",
    "#     print(f\"{dir_out}/{fn}.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad3493",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a9b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO? SpectralCoclustering\n",
    "\n",
    "# from sklearn.cluster import SpectralCoclustering\n",
    "\n",
    "# clustering = SpectralCoclustering().fit(im)\n",
    "\n",
    "# row = np.argsort(clustering.row_labels_)\n",
    "# col = np.argsort(clustering.column_labels_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b38a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3500a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "805a6658",
   "metadata": {},
   "source": [
    "## Save neuron top-n concept indices to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd239846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sim in similarity_load:\n",
    "#     layer_name = sim['layer']\n",
    "#     sim = sim['similarities'].argsort(descending=True)\n",
    "#     sim = sim[:,:100] ## get top\n",
    "#     sim = sim.type(torch.int32)\n",
    "#     fn = f'{dir_out}/concepts_top100_{layer_name}.npy'\n",
    "#     np.save(fn, sim.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d5757e",
   "metadata": {},
   "source": [
    "## Copy vocabulary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp data/20k.txt {dir_out}/vocabulary_20k.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca04d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0012f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
