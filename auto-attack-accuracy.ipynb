{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-v0_8-colorblind')\n",
    "\n",
    "\n",
    "import data_utils\n",
    "from autoattack import AutoAttack\n",
    "# (https://github.com/fra31/auto-attack/blob/master/autoattack/autoattack.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac7b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load model and defaalt image transform\n",
    "model, preprocess0 = data_utils.get_target_model(target_name='resnet50', device='cuda', weights='default')\n",
    "preprocess0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f63ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##transforms\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "normalize = transforms.Normalize(mean=preprocess0.mean, std=preprocess0.std)\n",
    "\n",
    "def denormalize(x):\n",
    "    std = torch.tensor(preprocess0.std).view(3,1,1)\n",
    "    mean = torch.tensor(preprocess0.mean).view(3,1,1)\n",
    "    x = x * std + mean # de-normalize\n",
    "    return x\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "\n",
    "## model forward pass\n",
    "def forward_pass(img):\n",
    "    img = normalize(img)\n",
    "    return model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e361b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = ImageFolder(\n",
    "# #     '/home/lim38/dataset/imagenet-val-attack/', \n",
    "#     '/home/lim38/dataset/imagenet-val/', \n",
    "# #     loader=lambda path: pathlib.Path(path).name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81350524",
   "metadata": {},
   "outputs": [],
   "source": [
    "##data, loader\n",
    "# dataset = data_utils.get_data('imagenet_val', preprocess)\n",
    "dataset = data_utils.get_data('imagenet_val_attack', preprocess=to_tensor)\n",
    "loader = DataLoader(dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, targets in tqdm(loader):\n",
    "        imgs, targets = imgs.cuda(), targets.cuda()\n",
    "        logits = forward_pass(imgs)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == targets).sum().item()\n",
    "        total += int(targets.shape[0])\n",
    "        print(f'{100*correct/total:.2f}%, {correct}/{total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c7f56f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
