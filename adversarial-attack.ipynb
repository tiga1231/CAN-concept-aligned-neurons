{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-v0_8-colorblind')\n",
    "\n",
    "\n",
    "import data_utils\n",
    "from autoattack import AutoAttack\n",
    "# (https://github.com/fra31/auto-attack/blob/master/autoattack/autoattack.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load model and defaalt image transform\n",
    "model, preprocess0 = data_utils.get_target_model(target_name='resnet50', device='cuda', weights='default')\n",
    "preprocess0\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##transforms\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "normalize = transforms.Normalize(mean=preprocess0.mean, std=preprocess0.std)\n",
    "\n",
    "def denormalize(x):\n",
    "    std = torch.tensor(preprocess0.std).view(3,1,1)\n",
    "    mean = torch.tensor(preprocess0.mean).view(3,1,1)\n",
    "    x = x * std + mean # de-normalize\n",
    "    return x\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data, loader\n",
    "dataset = data_utils.get_data('imagenet_val', preprocess)\n",
    "loader = DataLoader(dataset, batch_size=50, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inspect import getsource\n",
    "# print(getsource(model._forward_impl))\n",
    "\n",
    "# ## model forward pass\n",
    "# def forward_pass(img):\n",
    "#     img = normalize(img)\n",
    "#     return model(img)\n",
    "\n",
    "## model forward pass\n",
    "# def forward_pass(img):\n",
    "#     img = normalize(img)\n",
    "    \n",
    "#     x = img\n",
    "#     x = model.conv1(x)\n",
    "#     x = model.bn1(x)\n",
    "#     x = model.relu(x)\n",
    "#     x = model.maxpool(x)\n",
    "\n",
    "#     x = model.layer1(x)\n",
    "#     x = model.layer2(x)\n",
    "#     x = model.layer3(x)\n",
    "#     x = model.layer4(x)\n",
    "        \n",
    "#     return x\n",
    "\n",
    "forward_pass = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## disable model training\n",
    "for param in model.parameters():\n",
    "    param.requires_grad_(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(4,3)\n",
    "a.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_adversarial_examples(x, y, forward_pass, n_iter=10, vis=False, progress=True):\n",
    "    x = x.clone().requires_grad_(True)\n",
    "    optimizer = optim.SGD([x], lr=0.05)\n",
    "    \n",
    "    if progress:\n",
    "        pbar = tqdm(range(n_iter))\n",
    "    else:\n",
    "        pbar = range(n_iter)\n",
    "        \n",
    "#     with torch.no_grad():\n",
    "#         out = forward_pass(x)\n",
    "#         target = out.roll(shifts=1, dims=1).detach_()\n",
    "        \n",
    "    for i in pbar:\n",
    "        x.requires_grad_(True)\n",
    "        out = forward_pass(x)\n",
    "    \n",
    "        ## minimize logit of the right class\n",
    "        loss = out[torch.arange(x.shape[0]),y].sum()\n",
    "        ## minimize logit of the neighbor of right classes\n",
    "#         for i in range(-10,10):\n",
    "#             loss += out[torch.arange(x.shape[0]),(y+i)%1000].sum()/20\n",
    "        ## maximize logit of class + 500\n",
    "        loss += -out[torch.arange(x.shape[0]),(y+500)%1000].sum()\n",
    "        \n",
    "        # mute neurons\n",
    "#         loss = out.pow(2).sum()\n",
    "        # scramble neurons\n",
    "#         loss = (out-target).pow(2).sum()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         x.grad.data = x.grad.data.sign() # fast gradient sign\n",
    "        optimizer.step()\n",
    "        \n",
    "        x.detach_()\n",
    "#         x.clamp_(0,1)\n",
    "        if progress:\n",
    "            pbar.set_postfix({'loss':loss.item()})\n",
    "        \n",
    "        if vis:\n",
    "            image_i = 0\n",
    "            plt.subplot(131)\n",
    "            plt.imshow(x[image_i].permute(1,2,0).detach().cpu().numpy())\n",
    "#             plt.subplot(132)\n",
    "#             plt.imshow(out[1,0].detach().cpu().numpy())\n",
    "#             plt.colorbar()\n",
    "#             plt.subplot(133)\n",
    "#             plt.imshow(target[1,0].detach().cpu().numpy())\n",
    "#             plt.colorbar()\n",
    "            plt.subplot(132)\n",
    "            plt.stem(out[image_i].detach().cpu().numpy())\n",
    "            plt.show()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test for correctness\n",
    "\n",
    "img, target = next(iter(loader))\n",
    "img, target = img.cuda(), target.cuda()\n",
    "\n",
    "\n",
    "a = find_adversarial_examples(img, target, forward_pass, vis=True)\n",
    "\n",
    "print(model(img).argmax(1))\n",
    "print(model(a).argmax(1))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.stem(model(img)[1].detach().cpu().numpy())\n",
    "plt.subplot(122)\n",
    "plt.stem(model(a)[1].detach().cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/home/lim38/dataset/imagenet-val-attack'\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # global image count\n",
    "for k, [imgs, targets] in enumerate(tqdm(loader)):\n",
    "    imgs, targets = imgs.cuda(), targets.cuda()\n",
    "    advs = find_adversarial_examples(imgs, targets, forward_pass, vis=False, progress=False)\n",
    "    for a in advs:\n",
    "        pil = to_pil(a.detach().cpu())\n",
    "        subdir, fn = dataset.imgs[i][0].split('/')[-2:]\n",
    "        os.makedirs(f'{out_dir}/{subdir}', exist_ok=True)\n",
    "        pil.save(f'{out_dir}/{subdir}/{fn}')\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# abs_diff = (a - img).abs()\n",
    "# print('abs_diff.max', abs_diff.max())\n",
    "\n",
    "# for i in range(8):\n",
    "#     display(\n",
    "#         'orignal',\n",
    "#         to_pil(img[i].detach().cpu()), \n",
    "#         'orignal predict',\n",
    "#         model(img[i:i+1]).argmax(1),\n",
    "\n",
    "#         'adversarial',\n",
    "#         to_pil(a[i].detach().cpu()),\n",
    "#         'adversarial predict', \n",
    "#         model(a[i:i+1]).argmax(1),\n",
    "#         '============='\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_dir = '/home/lim38/dataset/imagenet-val-attack'\n",
    "# os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# # subdirs = set([img_and_label[0].split('/')[-2] for img_and_label in dataset.imgs])\n",
    "# # for subdir in subdirs:\n",
    "# #     os.makedirs(f'{out_dir}/{subdir}', exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adversary = AutoAttack(\n",
    "#     forward_pass, \n",
    "#     norm='Linf', \n",
    "#     eps=5/255, #bound over image domain [0,1]\n",
    "#     version='custom', \n",
    "#     attacks_to_run=['apgd-ce'],\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "# i = 0 # global image count\n",
    "# for img, target in tqdm(loader):\n",
    "    \n",
    "#     img, target = img.cuda(), target.cuda()\n",
    "#     adv = adversary.run_standard_evaluation(img, target)\n",
    "    \n",
    "#     for a in adv:\n",
    "#         pil = to_pil(a.detach().cpu())\n",
    "#         subdir, fn = dataset.imgs[i][0].split('/')[-2:]\n",
    "#         os.makedirs(f'{out_dir}/{subdir}', exist_ok=True)\n",
    "#         pil.save(f'{out_dir}/{subdir}/{fn}')\n",
    "#         i+=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
