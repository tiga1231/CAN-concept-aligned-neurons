{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d36de-ab56-4f3b-a81a-200aaf76b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "import utils\n",
    "import data_utils\n",
    "import similarity\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9114b41e",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724590a-2333-4daa-9948-6be1dfc60c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_name = 'ViT-B/16'\n",
    "target_name = 'resnet50'\n",
    "target_layer = 'layer4'\n",
    "d_probe = 'imagenet_broden'\n",
    "concept_set = 'data/20k.txt'\n",
    "batch_size = 200\n",
    "device = 'cuda'\n",
    "pool_mode = 'avg'\n",
    "\n",
    "save_dir = 'saved_activations'\n",
    "similarity_fn = similarity.soft_wpmi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c411a2f",
   "metadata": {},
   "source": [
    "## Run CLIP-Dissect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a1e91-5363-43a3-8f0b-4a034515923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_activations(clip_name = clip_name, target_name = target_name, target_layers = [target_layer], \n",
    "                       d_probe = d_probe, concept_set = concept_set, batch_size = batch_size, \n",
    "                       device = device, pool_mode=pool_mode, save_dir = save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0e205-0b81-4d59-80ac-16b321e56949",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_names = utils.get_save_names(clip_name = clip_name, target_name = target_name,\n",
    "                                  target_layer = target_layer, d_probe = d_probe,\n",
    "                                  concept_set = concept_set, pool_mode=pool_mode,\n",
    "                                  save_dir = save_dir)\n",
    "\n",
    "target_save_name, clip_save_name, text_save_name = save_names\n",
    "\n",
    "similarities, target_feats = utils.get_similarity_from_activations(target_save_name, clip_save_name, \n",
    "                                                             text_save_name, similarity_fn)\n",
    "\n",
    "with open(concept_set, 'r') as f: \n",
    "    words = (f.read()).split('\\n')\n",
    "\n",
    "pil_data = data_utils.get_data(d_probe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fe2008d",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d8bed-95bc-4c04-93f0-7629dc3f7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_to_check = ids_to_check = random.sample([i for i in range(target_feats.shape[1])], k=10)\n",
    "#neurons_to_check = torch.sort(torch.max(similarities, dim=1)[0], descending=True)[1][0:10]\n",
    "\n",
    "ranks = [\"1st\", \"2nd\", \"3rd\"]\n",
    "top_vals, top_ids = torch.topk(target_feats, k=5, dim=0)\n",
    "\n",
    "for orig_id in ids_to_check:\n",
    "\n",
    "    print('\\n Layer:{} Neuron:{}'.format(target_layer, (int(orig_id))))\n",
    "    vals, ids = torch.topk(similarities[orig_id], k=3, largest=True)\n",
    "    for i in range(len(vals)):\n",
    "        print(\"{} description: {}, sim:{:.3f}\".format(ranks[i], words[int(ids[i])], vals[i]))\n",
    "    \n",
    "    print(\"5 most highly activating images in D_probe:\")\n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "    for i, top_id in enumerate(top_ids[:, orig_id]):\n",
    "        im, label = pil_data[top_id]\n",
    "        im = im.resize([375,375])\n",
    "        fig.add_subplot(1, 5, i+1)\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.title('Layer:{} Neuron:{}'.format(target_layer, (int(orig_id))))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d93e8-9b14-4786-bd56-ba0ae56b6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_to_check = torch.sort(torch.max(similarities, dim=1)[0], descending=True)[1][0:10]\n",
    "font_size=14\n",
    "font = {'size'   : font_size}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "fig = plt.figure(figsize=[10, len(neurons_to_check)*2])#constrained_layout=True)\n",
    "subfigs = fig.subfigures(nrows=len(neurons_to_check), ncols=1)\n",
    "for j, orig_id in enumerate(neurons_to_check):\n",
    "    vals, ids = torch.topk(similarities[orig_id], k=5, largest=True)\n",
    "        \n",
    "    subfig = subfigs[j]\n",
    "    subfig.text(0.13, 0.96, \"Neuron {}:\".format(int(orig_id)), size=font_size)\n",
    "    subfig.text(0.27, 0.96, \"CLIP-Dissect:\", size=font_size)\n",
    "    subfig.text(0.4, 0.96, words[int(ids[0])], size=font_size)\n",
    "    axs = subfig.subplots(nrows=1, ncols=5)\n",
    "    for i, top_id in enumerate(top_ids[:, orig_id]):\n",
    "        im, label = pil_data[top_id]\n",
    "        im = im.resize([375,375])\n",
    "        axs[i].imshow(im)\n",
    "        axs[i].axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
